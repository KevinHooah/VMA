{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdcution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook for discussing the future directions of this project.\n",
    "Please be notified, this is **_NOT_** the feature **_NOR_** the model used for the IPSN 2022 VMA paper.\n",
    "The aim of this paper is becaues I envision the future of sensory-based Human Activity Recognition consists of encoder-decoder structures. The representation learning for all the down-stream task will be the near future. In the VMA paper, we utilize the hand-crafted feature and concatenate them together, which is quite limited. Also, the adoption of different segmentation technique make it qutie annoying in the fusion step. In this way, I want to explore, can we leverage physcial knowledge to conduct some feature extraction and them fit into the VMA framework?\n",
    "\n",
    "This note book is different with in `demo_paper.ipynb` in (but not limited to) following points:\n",
    "- It dosen't adpot hand-crafted feature. It's based on feature extrator network. This notebook may be kept updating, so the backbone is not fixed as I'm writing now.\n",
    "- The vibration signal is processed with sliding window segementation at the beginning. Therefore, you dont't need all these MATLAB-based fusion codes. You can easliy do the confidence thresholding and pseudo-labeled data selection with numpy indexing.\n",
    "- There is not any spatial analysis-based model. I just code one model for all activities.\n",
    "- This notebook is highly possible to be unfinished/bad. I don't have too much time to build a very powerful model, that's not the contribution of the project. You may see the current model achieves a 0% accuracy. I just want to use this notebook to show more possibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Coded by Kevin Hu.\n",
    "Contact: www.kevin-hu.com\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epoch = 100\n",
    "l_r = 0.001\n",
    "window_size = int(6500*1.5)\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_mat('./raw_data/person_1_location_1.mat')\n",
    "inter_data = read_mat('./raw_data/person_1_location_2.mat')\n",
    "test_data = read_mat('./raw_data/person_2_location_2.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imu, train_vib =  prepare_tf_data(train_data, window_size, batch_size)\n",
    "inter_imu, inter_vib =  prepare_tf_data(inter_data, window_size, batch_size)\n",
    "test_imu, test_vib =  prepare_tf_data(test_data, window_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_i = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "loss_v = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "opt_i= keras.optimizers.Adam(learning_rate=l_r)\n",
    "opt_v= keras.optimizers.Adam(learning_rate=l_r)\n",
    "\n",
    "train_acc_metric = keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "share_input = layers.Input(shape=(128,))\n",
    "s_1 = layers.Dense(64, activation=\"elu\", name = 'share_1')(share_input)\n",
    "s_1 = layers.Dropout(0.5)(s_1)\n",
    "s_2 = layers.Dense(32, activation=\"elu\", name = 'share_2')(s_1)\n",
    "s_2 = layers.Dropout(0.5)(s_2)\n",
    "shared_layers = keras.Model(inputs=share_input, outputs=s_2, name=\"middle_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_i = layers.Input((window_size, 6))\n",
    "input_v = layers.Input((window_size, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imu_encoder\n",
    "x_i = layers.Conv1D(64, 5, activation=\"elu\")(input_i)\n",
    "x_i = layers.BatchNormalization()(x_i)\n",
    "x_i = layers.Conv1D(64, 5, activation=\"elu\")(x_i)\n",
    "x_i = layers.MaxPooling1D(pool_size=2)(x_i)\n",
    "x_i = layers.Flatten()(x_i)\n",
    "x_i = layers.BatchNormalization()(x_i)\n",
    "x_i = layers.Dense(128, activation=\"elu\")(x_i)\n",
    "\n",
    "#vib_encoder\n",
    "x_v = layers.Conv1D(64, 5, activation=\"elu\")(input_v)\n",
    "x_v = layers.BatchNormalization()(x_v)\n",
    "x_v = layers.Conv1D(64, 5, activation=\"elu\")(x_v)\n",
    "x_v = layers.MaxPooling1D(pool_size=2)(x_v)\n",
    "x_v = layers.Flatten()(x_v)\n",
    "x_v = layers.BatchNormalization()(x_v)\n",
    "x_v = layers.Dense(128, activation=\"elu\")(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_imu = shared_layers(x_i)\n",
    "x_vib = shared_layers(x_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_i = layers.Dense(10)(x_imu)\n",
    "output_v = layers.Dense(10)(x_vib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_i = keras.Model(inputs=input_i, outputs=output_i, name=\"imu_model\")\n",
    "model_v = keras.Model(inputs=input_v, outputs=output_v, name=\"vib_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_i = list()\n",
    "val_loss_i = list()\n",
    "train_loss_v = list()\n",
    "val_loss_v = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epoch):\n",
    "    if verbose:\n",
    "        print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train_i, y_batch_train_i) in enumerate(train_imu):\n",
    "        y_batch_train_i = tf.keras.utils.to_categorical(y_batch_train_i, num_classes=10, dtype='float32')\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits_i = model_i(x_batch_train_i, training=True)  # Logits for this minibatch\n",
    "            loss_value_i = loss_i(y_batch_train_i, logits_i)\n",
    "        grads_i = tape.gradient(loss_value_i, model_i.trainable_weights)\n",
    "        opt_i.apply_gradients(zip(grads_i, model_i.trainable_weights))\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Training loss of model_i at epoch %d: %.4f\" % (epoch + 1, float(loss_value_i)))\n",
    "\n",
    "    for x_batch_val_i, y_batch_val_i in inter_imu:\n",
    "        y_batch_val_i = tf.keras.utils.to_categorical(y_batch_val_i, num_classes=10, dtype='float32')\n",
    "        val_logits_i = model_i(x_batch_val_i, training=False)\n",
    "        val_loss_value_i = loss_i(y_batch_val_i, val_logits_i)\n",
    "    if verbose:\n",
    "        print(\"Val loss of model_i at epoch %d: %.4f\"% (epoch + 1, float(val_loss_value_i)))\n",
    "    train_loss_i.append(float(loss_value_i))\n",
    "    val_loss_i.append(float(val_loss_value_i))\n",
    "\n",
    "    for step, (x_batch_train_v, y_batch_train_v) in enumerate(train_vib):\n",
    "        y_batch_train_v = tf.keras.utils.to_categorical(y_batch_train_v, num_classes=10, dtype='float32')\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits_v = model_v(x_batch_train_v, training=True)  # Logits for this minibatch\n",
    "            loss_value_v = loss_v(y_batch_train_v, logits_v)\n",
    "        grads_v = tape.gradient(loss_value_v, model_v.trainable_weights)\n",
    "        opt_v.apply_gradients(zip(grads_v, model_v.trainable_weights))\n",
    "    if verbose:\n",
    "        print(\"Training loss of model_v at epoch %d: %.4f\"% (epoch + 1, float(loss_value_v)))\n",
    "\n",
    "    for x_batch_val_v, y_batch_val_v in inter_vib:\n",
    "        y_batch_val_v = tf.keras.utils.to_categorical(y_batch_val_v, num_classes=10, dtype='float32')\n",
    "        val_logits_v = model_v(x_batch_val_v, training=False)\n",
    "        val_loss_value_v = loss_v(y_batch_val_v, val_logits_v)\n",
    "    if verbose:\n",
    "        print(\"Val loss of model_v at epoch %d: %.4f\"% (epoch + 1, float(val_loss_value_v)))\n",
    "    train_loss_v.append(float(loss_value_v))\n",
    "    val_loss_v.append(float(val_loss_value_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_i)\n",
    "plt.plot(val_loss_i)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"IMU Loss\")\n",
    "plt.legend(['Train Loss', 'Val Loss'])\n",
    "plt.ylim([0, 4])\n",
    "plt.show()\n",
    "\n",
    "plt.plot(train_loss_v)\n",
    "plt.plot(val_loss_v)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.title(\"Vibration Loss\")\n",
    "plt.legend(['Train Loss', 'Val Loss'])\n",
    "plt.ylim([0, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_imu, tf_vib =  prepare_tf_data(inter_data, window_size, 1)\n",
    "X_inter_imu, y_inter_imu = prepare_np_data(tf_imu, window_size, 6)\n",
    "X_inter_vib, y_inter_vib = prepare_np_data(tf_vib, window_size, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vib_conf_mat = np.zeros((tf_vib.cardinality().numpy(),10))\n",
    "imu_conf_mat = np.zeros((tf_imu.cardinality().numpy(),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = tf.keras.layers.Activation('softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vibration train acc: 0.2629\n"
     ]
    }
   ],
   "source": [
    "val_acc_metric.reset_states()\n",
    "for idx, (x_batch_val_v, y_batch_val_v) in enumerate(tf_vib):\n",
    "        y_batch_val_v = tf.keras.utils.to_categorical(y_batch_val_v, num_classes=10, dtype='float32')\n",
    "        val_logits_v = model_v(x_batch_val_v, training=False)\n",
    "        output = layer(val_logits_v)\n",
    "        pred_logit = output.numpy()\n",
    "        vib_conf_mat[idx] = pred_logit\n",
    "        val_acc_metric.update_state(y_batch_val_v , val_logits_v)\n",
    "        # val_acc_metric.reset_states()\n",
    "        # break\n",
    "\n",
    "val_acc_v = val_acc_metric.result()\n",
    "print(\"Vibration train acc: %.4f\" % (float(val_acc_v),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU train acc: 0.3079\n"
     ]
    }
   ],
   "source": [
    "val_acc_metric.reset_states()\n",
    "for x_batch_val_i, y_batch_val_i in tf_imu:\n",
    "        y_batch_val_i = tf.keras.utils.to_categorical(y_batch_val_i, num_classes=10, dtype='float32')\n",
    "        val_logits_i = model_i(x_batch_val_i, training=False) \n",
    "        output = layer(val_logits_i)\n",
    "        pred_logit = output.numpy()\n",
    "        imu_conf_mat[idx] = pred_logit\n",
    "        val_acc_metric.update_state(y_batch_val_i , val_logits_i)\n",
    "        # break\n",
    "\n",
    "val_acc_i = val_acc_metric.result()\n",
    "print(\"IMU train acc: %.4f\" % (float(val_acc_i),))\n",
    "val_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, not so good right now..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e169a1c1b98568d4a7e285a40e2e83db3750054f846b911e83b0804d146323dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
